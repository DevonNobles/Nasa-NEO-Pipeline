INFO:src.minio_client:Creating MinIO client for endpoint: localhost:9000
DEBUG:src.minio_client:MinIO client instance created successfully
INFO:src.minio_client:Validating MinIO connection...
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9000
DEBUG:urllib3.connectionpool:http://localhost:9000 "GET / HTTP/1.1" 200 0
INFO:src.minio_client:MinIO connection validated successfully
DEBUG:__main__:Initializing NeoApiClient for date range 2025-05-02 to 2025-05-09
DEBUG:__main__:NeoApiClient initialized for bucket 'neo' in bronze mode
INFO:__main__:Starting data extraction for mode: bronze
DEBUG:__main__:Making API request to: https://api.nasa.gov/neo/rest/v1/feed?start_date=2025-05-02&end_date=2025-05-09&api_key=Sfn0wfG6FG6E3D5Hu8MrxSja38yMXftWqboKv6ZH
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.nasa.gov:443
DEBUG:urllib3.connectionpool:https://api.nasa.gov:443 "GET /neo/rest/v1/feed?start_date=2025-05-02&end_date=2025-05-09&api_key=Sfn0wfG6FG6E3D5Hu8MrxSja38yMXftWqboKv6ZH HTTP/1.1" 200 None
INFO:__main__:Successfully extracted 153288 bytes from NASA API
INFO:__main__:Data extraction completed successfully for mode: bronze
INFO:__main__:Starting data transformation for mode: bronze
INFO:__main__:Bronze mode: No transformation required
INFO:__main__:Data transformation completed successfully for mode: bronze
INFO:__main__:Starting data load for mode: bronze
DEBUG:urllib3.connectionpool:http://localhost:9000 "GET /neo?location= HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:http://localhost:9000 "PUT /neo/bronze/neo-2025-05-02_2025-05-09.json HTTP/1.1" 200 0
DEBUG:__main__:Queue operation: mode=in, object_name=bronze/neo-2025-05-02_2025-05-09.json
INFO:src.queue_manager:Adding 'bronze/neo-2025-05-02_2025-05-09.json' to queue 'queue'
INFO:src.queue_manager:Successfully added 'bronze/neo-2025-05-02_2025-05-09.json' to queue
INFO:__main__:Successfully stored bronze/neo-2025-05-02_2025-05-09.json and added to queue
INFO:__main__:Data load completed successfully for mode: bronze
DEBUG:__main__:Initializing NeoApiClient for date range 2025-05-02 to 2025-05-09
DEBUG:__main__:NeoApiClient initialized for bucket 'neo' in silver mode
INFO:__main__:Starting data extraction for mode: silver
DEBUG:__main__:Extracting data from bronze storage
DEBUG:__main__:Queue operation: mode=out, object_name=None
DEBUG:src.queue_manager:Getting item from queue 'queue'
INFO:src.queue_manager:Retrieved 'bronze/neo-2025-05-02_2025-05-09.json' from queue
DEBUG:__main__:Retrieving object: bronze/neo-2025-05-02_2025-05-09.json
DEBUG:urllib3.connectionpool:http://localhost:9000 "GET /neo/bronze/neo-2025-05-02_2025-05-09.json HTTP/1.1" 200 153288
INFO:__main__:Successfully extracted object 'bronze/neo-2025-05-02_2025-05-09.json' from bronze storage
INFO:__main__:Data extraction completed successfully for mode: silver
INFO:__main__:Starting data transformation for mode: silver
DEBUG:__main__:Using processing mode: silver
DEBUG:__main__:Building Spark configuration for mode: silver
DEBUG:__main__:Built configuration with 16 settings
DEBUG:py4j.java_gateway:GatewayClient.address is deprecated and will be removed in version 1.0. Use GatewayParameters instead.
DEBUG:py4j.clientserver:Command to send: A
8db796b1b48f0b07676944df940a01850b4373ef0aac66f1b3cba4831e37bc68

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.SparkConf
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.api.java.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.api.python.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.ml.python.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.mllib.api.python.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.resource.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.sql.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.sql.api.python.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
org.apache.spark.sql.hive.*
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: j
i
rj
scala.Tuple2
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: r
u
SparkConf
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkConf
DEBUG:py4j.clientserver:Command to send: i
org.apache.spark.SparkConf
bTrue
e

DEBUG:py4j.clientserver:Answer received: !yro0
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.app.name
sNASA_NEO_Silver_Data
e

DEBUG:py4j.clientserver:Answer received: !yro1
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.jars.packages
sorg.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.1,org.apache.hadoop:hadoop-aws:3.4.1,org.apache.hadoop:hadoop-common:3.4.1,org.apache.iceberg:iceberg-aws-bundle:1.9.1
e

DEBUG:py4j.clientserver:Answer received: !yro2
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.sql.extensions
sorg.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
e

DEBUG:py4j.clientserver:Answer received: !yro3
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.sql.catalog.iceberg_catalog
sorg.apache.iceberg.spark.SparkCatalog
e

DEBUG:py4j.clientserver:Answer received: !yro4
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.sql.catalog.iceberg_catalog.type
shadoop
e

DEBUG:py4j.clientserver:Answer received: !yro5
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.sql.catalog.iceberg_catalog.warehouse
ss3a://neo
e

DEBUG:py4j.clientserver:Answer received: !yro6
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.sql.catalog.iceberg_catalog.io-impl
sorg.apache.iceberg.aws.s3.S3FileIO
e

DEBUG:py4j.clientserver:Answer received: !yro7
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.endpoint
shttp://localhost:9000
e

DEBUG:py4j.clientserver:Answer received: !yro8
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.access.key
sminioadmin
e

DEBUG:py4j.clientserver:Answer received: !yro9
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.secret.key
sminioadmin
e

DEBUG:py4j.clientserver:Answer received: !yro10
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.path.style.access
strue
e

DEBUG:py4j.clientserver:Answer received: !yro11
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.connection.ssl.enabled
sfalse
e

DEBUG:py4j.clientserver:Answer received: !yro12
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.impl
sorg.apache.hadoop.fs.s3a.S3AFileSystem
e

DEBUG:py4j.clientserver:Answer received: !yro13
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.hadoop.fs.s3a.aws.credentials.provider
sorg.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
e

DEBUG:py4j.clientserver:Answer received: !yro14
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.sql.adaptive.enabled
sfalse
e

DEBUG:py4j.clientserver:Answer received: !yro15
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.serializer
sorg.apache.spark.serializer.KryoSerializer
e

DEBUG:py4j.clientserver:Answer received: !yro16
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.serializer.objectStreamReset
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.serializer.objectStreamReset
s100
e

DEBUG:py4j.clientserver:Answer received: !yro17
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.rdd.compress
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: c
o0
set
sspark.rdd.compress
sTrue
e

DEBUG:py4j.clientserver:Answer received: !yro18
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.master
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.app.name
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.master
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o0
get
sspark.master
e

DEBUG:py4j.clientserver:Answer received: !yslocal[*]
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.app.name
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o0
get
sspark.app.name
e

DEBUG:py4j.clientserver:Answer received: !ysNASA_NEO_Silver_Data
DEBUG:py4j.clientserver:Command to send: c
o0
contains
sspark.home
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: c
o0
getAll
e

DEBUG:py4j.clientserver:Answer received: !yto19
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i0
e

DEBUG:py4j.clientserver:Answer received: !yro20
DEBUG:py4j.clientserver:Command to send: c
o20
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.repl.local.jars
DEBUG:py4j.clientserver:Command to send: c
o20
_2
e

DEBUG:py4j.clientserver:Answer received: !ysfile:///home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-common-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-aws-bundle-1.9.1.jar,file:///home/fastnnefarious/.ivy2/jars/software.amazon.awssdk_bundle-2.24.6.jar,file:///home/fastnnefarious/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-protobuf_3_25-1.3.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.3.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_guava-27.0-jre.jar,file:///home/fastnnefarious/.ivy2/jars/commons-cli_commons-cli-1.5.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/fastnnefarious/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/fastnnefarious/.ivy2/jars/commons-io_commons-io-2.16.1.jar,file:///home/fastnnefarious/.ivy2/jars/commons-net_commons-net-3.9.0.jar,file:///home/fastnnefarious/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar,file:///home/fastnnefarious/.ivy2/jars/javax.servlet_javax.servlet-api-3.1.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-server-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-servlet-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-webapp-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-core-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-servlet-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.github.pjfanning_jersey-json-1.22.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.jettison_jettison-1.5.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-server-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/ch.qos.reload4j_reload4j-1.2.22.jar,file:///home/fastnnefarious/.ivy2/jars/commons-beanutils_commons-beanutils-1.9.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-configuration2-2.10.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-lang3-3.12.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-text-1.10.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,file:///home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-reload4j-1.7.36.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.avro_avro-1.9.2.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.re2j_re2j-1.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.code.gson_gson-2.9.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-auth-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.jcraft_jsch-0.1.55.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-client-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-recipes-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-3.8.4.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-handler-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-epoll-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.dropwizard.metrics_metrics-core-3.2.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-compress-1.26.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.bouncycastle_bcprov-jdk18on-1.78.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-core-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.7.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.woodstox_stax2-api-4.2.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.woodstox_woodstox-core-5.4.0.jar,file:///home/fastnnefarious/.ivy2/jars/dnsjava_dnsjava-3.6.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_failureaccess-1.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,file:///home/fastnnefarious/.ivy2/jars/org.checkerframework_checker-qual-2.5.2.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.17.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/fastnnefarious/.ivy2/jars/commons-logging_commons-logging-1.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-http-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-io-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-security-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-xml-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/javax.ws.rs_jsr311-api-1.1.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.xml.bind_jaxb-impl-2.2.3-1.jar,file:///home/fastnnefarious/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.7.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.7.jar,file:///home/fastnnefarious/.ivy2/jars/com.nimbusds_nimbus-jose-jwt-9.37.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-framework-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-util-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-jute-3.8.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.yetus_audience-annotations-0.12.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-pkix-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-asn1-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-util-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-config-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-crypto-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-common-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-resolver-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-buffer-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-unix-common-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-codec-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-classes-epoll-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/jakarta.activation_jakarta.activation-api-1.2.1.jar,file:///home/fastnnefarious/.ivy2/jars/javax.servlet.jsp_jsp-api-2.1.jar
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i1
e

DEBUG:py4j.clientserver:Answer received: !yro21
DEBUG:py4j.clientserver:Command to send: c
o21
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.connection.ssl.enabled
DEBUG:py4j.clientserver:Command to send: c
o21
_2
e

DEBUG:py4j.clientserver:Answer received: !ysfalse
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i2
e

DEBUG:py4j.clientserver:Answer received: !yro22
DEBUG:py4j.clientserver:Command to send: c
o22
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.path.style.access
DEBUG:py4j.clientserver:Command to send: c
o22
_2
e

DEBUG:py4j.clientserver:Answer received: !ystrue
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i3
e

DEBUG:py4j.clientserver:Answer received: !yro23
DEBUG:py4j.clientserver:Command to send: c
o23
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.submit.pyFiles
DEBUG:py4j.clientserver:Command to send: c
o23
_2
e

DEBUG:py4j.clientserver:Answer received: !ys/home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-common-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-aws-bundle-1.9.1.jar,/home/fastnnefarious/.ivy2/jars/software.amazon.awssdk_bundle-2.24.6.jar,/home/fastnnefarious/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-protobuf_3_25-1.3.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.3.0.jar,/home/fastnnefarious/.ivy2/jars/com.google.guava_guava-27.0-jre.jar,/home/fastnnefarious/.ivy2/jars/commons-cli_commons-cli-1.5.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,/home/fastnnefarious/.ivy2/jars/commons-codec_commons-codec-1.15.jar,/home/fastnnefarious/.ivy2/jars/commons-io_commons-io-2.16.1.jar,/home/fastnnefarious/.ivy2/jars/commons-net_commons-net-3.9.0.jar,/home/fastnnefarious/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar,/home/fastnnefarious/.ivy2/jars/javax.servlet_javax.servlet-api-3.1.0.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-server-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-servlet-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-webapp-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-core-1.19.4.jar,/home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-servlet-1.19.4.jar,/home/fastnnefarious/.ivy2/jars/com.github.pjfanning_jersey-json-1.22.0.jar,/home/fastnnefarious/.ivy2/jars/org.codehaus.jettison_jettison-1.5.4.jar,/home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-server-1.19.4.jar,/home/fastnnefarious/.ivy2/jars/ch.qos.reload4j_reload4j-1.2.22.jar,/home/fastnnefarious/.ivy2/jars/commons-beanutils_commons-beanutils-1.9.4.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-configuration2-2.10.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-lang3-3.12.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-text-1.10.0.jar,/home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,/home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-reload4j-1.7.36.jar,/home/fastnnefarious/.ivy2/jars/org.apache.avro_avro-1.9.2.jar,/home/fastnnefarious/.ivy2/jars/com.google.re2j_re2j-1.1.jar,/home/fastnnefarious/.ivy2/jars/com.google.code.gson_gson-2.9.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-auth-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/com.jcraft_jsch-0.1.55.jar,/home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-client-5.2.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-recipes-5.2.0.jar,/home/fastnnefarious/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar,/home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-3.8.4.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-handler-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-epoll-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.dropwizard.metrics_metrics-core-3.2.4.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-compress-1.26.1.jar,/home/fastnnefarious/.ivy2/jars/org.bouncycastle_bcprov-jdk18on-1.78.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-core-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.7.1.jar,/home/fastnnefarious/.ivy2/jars/org.codehaus.woodstox_stax2-api-4.2.1.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.woodstox_woodstox-core-5.4.0.jar,/home/fastnnefarious/.ivy2/jars/dnsjava_dnsjava-3.6.1.jar,/home/fastnnefarious/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.4.jar,/home/fastnnefarious/.ivy2/jars/com.google.guava_failureaccess-1.0.jar,/home/fastnnefarious/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/fastnnefarious/.ivy2/jars/org.checkerframework_checker-qual-2.5.2.jar,/home/fastnnefarious/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,/home/fastnnefarious/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.17.jar,/home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,/home/fastnnefarious/.ivy2/jars/commons-logging_commons-logging-1.2.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-http-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-io-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-security-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-xml-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/javax.ws.rs_jsr311-api-1.1.1.jar,/home/fastnnefarious/.ivy2/jars/com.sun.xml.bind_jaxb-impl-2.2.3-1.jar,/home/fastnnefarious/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.7.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.7.jar,/home/fastnnefarious/.ivy2/jars/com.nimbusds_nimbus-jose-jwt-9.37.2.jar,/home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-framework-5.2.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-util-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-jute-3.8.4.jar,/home/fastnnefarious/.ivy2/jars/org.apache.yetus_audience-annotations-0.12.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-pkix-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-asn1-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-util-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-config-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-crypto-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-common-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-resolver-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-buffer-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-unix-common-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-codec-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-classes-epoll-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/jakarta.activation_jakarta.activation-api-1.2.1.jar,/home/fastnnefarious/.ivy2/jars/javax.servlet.jsp_jsp-api-2.1.jar
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i4
e

DEBUG:py4j.clientserver:Answer received: !yro24
DEBUG:py4j.clientserver:Command to send: c
o24
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.app.name
DEBUG:py4j.clientserver:Command to send: c
o24
_2
e

DEBUG:py4j.clientserver:Answer received: !ysNASA_NEO_Silver_Data
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i5
e

DEBUG:py4j.clientserver:Answer received: !yro25
DEBUG:py4j.clientserver:Command to send: c
o25
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.app.submitTime
DEBUG:py4j.clientserver:Command to send: c
o25
_2
e

DEBUG:py4j.clientserver:Answer received: !ys1748635318517
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i6
e

DEBUG:py4j.clientserver:Answer received: !yro26
DEBUG:py4j.clientserver:Command to send: c
o26
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.aws.credentials.provider
DEBUG:py4j.clientserver:Command to send: c
o26
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i7
e

DEBUG:py4j.clientserver:Answer received: !yro27
DEBUG:py4j.clientserver:Command to send: c
o27
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.endpoint
DEBUG:py4j.clientserver:Command to send: c
o27
_2
e

DEBUG:py4j.clientserver:Answer received: !yshttp://localhost:9000
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i8
e

DEBUG:py4j.clientserver:Answer received: !yro28
DEBUG:py4j.clientserver:Command to send: c
o28
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.sql.catalog.iceberg_catalog.warehouse
DEBUG:py4j.clientserver:Command to send: c
o28
_2
e

DEBUG:py4j.clientserver:Answer received: !yss3a://neo
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i9
e

DEBUG:py4j.clientserver:Answer received: !yro29
DEBUG:py4j.clientserver:Command to send: c
o29
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.jars.packages
DEBUG:py4j.clientserver:Command to send: c
o29
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.1,org.apache.hadoop:hadoop-aws:3.4.1,org.apache.hadoop:hadoop-common:3.4.1,org.apache.iceberg:iceberg-aws-bundle:1.9.1
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i10
e

DEBUG:py4j.clientserver:Answer received: !yro30
DEBUG:py4j.clientserver:Command to send: c
o30
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.files
DEBUG:py4j.clientserver:Command to send: c
o30
_2
e

DEBUG:py4j.clientserver:Answer received: !ysfile:///home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-common-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-aws-bundle-1.9.1.jar,file:///home/fastnnefarious/.ivy2/jars/software.amazon.awssdk_bundle-2.24.6.jar,file:///home/fastnnefarious/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-protobuf_3_25-1.3.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.3.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_guava-27.0-jre.jar,file:///home/fastnnefarious/.ivy2/jars/commons-cli_commons-cli-1.5.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/fastnnefarious/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/fastnnefarious/.ivy2/jars/commons-io_commons-io-2.16.1.jar,file:///home/fastnnefarious/.ivy2/jars/commons-net_commons-net-3.9.0.jar,file:///home/fastnnefarious/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar,file:///home/fastnnefarious/.ivy2/jars/javax.servlet_javax.servlet-api-3.1.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-server-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-servlet-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-webapp-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-core-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-servlet-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.github.pjfanning_jersey-json-1.22.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.jettison_jettison-1.5.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-server-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/ch.qos.reload4j_reload4j-1.2.22.jar,file:///home/fastnnefarious/.ivy2/jars/commons-beanutils_commons-beanutils-1.9.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-configuration2-2.10.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-lang3-3.12.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-text-1.10.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,file:///home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-reload4j-1.7.36.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.avro_avro-1.9.2.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.re2j_re2j-1.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.code.gson_gson-2.9.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-auth-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.jcraft_jsch-0.1.55.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-client-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-recipes-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-3.8.4.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-handler-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-epoll-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.dropwizard.metrics_metrics-core-3.2.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-compress-1.26.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.bouncycastle_bcprov-jdk18on-1.78.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-core-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.7.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.woodstox_stax2-api-4.2.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.woodstox_woodstox-core-5.4.0.jar,file:///home/fastnnefarious/.ivy2/jars/dnsjava_dnsjava-3.6.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_failureaccess-1.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,file:///home/fastnnefarious/.ivy2/jars/org.checkerframework_checker-qual-2.5.2.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.17.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/fastnnefarious/.ivy2/jars/commons-logging_commons-logging-1.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-http-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-io-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-security-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-xml-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/javax.ws.rs_jsr311-api-1.1.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.xml.bind_jaxb-impl-2.2.3-1.jar,file:///home/fastnnefarious/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.7.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.7.jar,file:///home/fastnnefarious/.ivy2/jars/com.nimbusds_nimbus-jose-jwt-9.37.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-framework-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-util-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-jute-3.8.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.yetus_audience-annotations-0.12.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-pkix-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-asn1-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-util-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-config-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-crypto-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-common-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-resolver-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-buffer-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-unix-common-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-codec-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-classes-epoll-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/jakarta.activation_jakarta.activation-api-1.2.1.jar,file:///home/fastnnefarious/.ivy2/jars/javax.servlet.jsp_jsp-api-2.1.jar
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i11
e

DEBUG:py4j.clientserver:Answer received: !yro31
DEBUG:py4j.clientserver:Command to send: c
o31
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.sql.extensions
DEBUG:py4j.clientserver:Command to send: c
o31
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i12
e

DEBUG:py4j.clientserver:Answer received: !yro32
DEBUG:py4j.clientserver:Command to send: c
o32
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.jars
DEBUG:py4j.clientserver:Command to send: c
o32
_2
e

DEBUG:py4j.clientserver:Answer received: !ysfile:///home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-common-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-aws-bundle-1.9.1.jar,file:///home/fastnnefarious/.ivy2/jars/software.amazon.awssdk_bundle-2.24.6.jar,file:///home/fastnnefarious/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-protobuf_3_25-1.3.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.3.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_guava-27.0-jre.jar,file:///home/fastnnefarious/.ivy2/jars/commons-cli_commons-cli-1.5.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/fastnnefarious/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/fastnnefarious/.ivy2/jars/commons-io_commons-io-2.16.1.jar,file:///home/fastnnefarious/.ivy2/jars/commons-net_commons-net-3.9.0.jar,file:///home/fastnnefarious/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar,file:///home/fastnnefarious/.ivy2/jars/javax.servlet_javax.servlet-api-3.1.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-server-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-servlet-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-webapp-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-core-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-servlet-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.github.pjfanning_jersey-json-1.22.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.jettison_jettison-1.5.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-server-1.19.4.jar,file:///home/fastnnefarious/.ivy2/jars/ch.qos.reload4j_reload4j-1.2.22.jar,file:///home/fastnnefarious/.ivy2/jars/commons-beanutils_commons-beanutils-1.9.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-configuration2-2.10.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-lang3-3.12.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-text-1.10.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,file:///home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-reload4j-1.7.36.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.avro_avro-1.9.2.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.re2j_re2j-1.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.code.gson_gson-2.9.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-auth-3.4.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.jcraft_jsch-0.1.55.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-client-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-recipes-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-3.8.4.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-handler-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-epoll-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.dropwizard.metrics_metrics-core-3.2.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-compress-1.26.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.bouncycastle_bcprov-jdk18on-1.78.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-core-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.7.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.woodstox_stax2-api-4.2.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.woodstox_woodstox-core-5.4.0.jar,file:///home/fastnnefarious/.ivy2/jars/dnsjava_dnsjava-3.6.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.4.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_failureaccess-1.0.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,file:///home/fastnnefarious/.ivy2/jars/org.checkerframework_checker-qual-2.5.2.jar,file:///home/fastnnefarious/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,file:///home/fastnnefarious/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.17.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/fastnnefarious/.ivy2/jars/commons-logging_commons-logging-1.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-http-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-io-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-security-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-xml-9.4.53.v20231009.jar,file:///home/fastnnefarious/.ivy2/jars/javax.ws.rs_jsr311-api-1.1.1.jar,file:///home/fastnnefarious/.ivy2/jars/com.sun.xml.bind_jaxb-impl-2.2.3-1.jar,file:///home/fastnnefarious/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.7.jar,file:///home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.7.jar,file:///home/fastnnefarious/.ivy2/jars/com.nimbusds_nimbus-jose-jwt-9.37.2.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-framework-5.2.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-util-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-jute-3.8.4.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.yetus_audience-annotations-0.12.0.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-pkix-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-asn1-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-util-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-config-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-crypto-2.0.3.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-common-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-resolver-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-buffer-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-unix-common-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-codec-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-classes-epoll-4.1.100.Final.jar,file:///home/fastnnefarious/.ivy2/jars/jakarta.activation_jakarta.activation-api-1.2.1.jar,file:///home/fastnnefarious/.ivy2/jars/javax.servlet.jsp_jsp-api-2.1.jar
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i13
e

DEBUG:py4j.clientserver:Answer received: !yro33
DEBUG:py4j.clientserver:Command to send: c
o33
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.serializer
DEBUG:py4j.clientserver:Command to send: c
o33
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.spark.serializer.KryoSerializer
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i14
e

DEBUG:py4j.clientserver:Answer received: !yro34
DEBUG:py4j.clientserver:Command to send: c
o34
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.impl
DEBUG:py4j.clientserver:Command to send: c
o34
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.hadoop.fs.s3a.S3AFileSystem
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i15
e

DEBUG:py4j.clientserver:Answer received: !yro35
DEBUG:py4j.clientserver:Command to send: c
o35
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.sql.catalog.iceberg_catalog
DEBUG:py4j.clientserver:Command to send: c
o35
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.iceberg.spark.SparkCatalog
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i16
e

DEBUG:py4j.clientserver:Answer received: !yro36
DEBUG:py4j.clientserver:Command to send: c
o36
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.rdd.compress
DEBUG:py4j.clientserver:Command to send: c
o36
_2
e

DEBUG:py4j.clientserver:Answer received: !ysTrue
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i17
e

DEBUG:py4j.clientserver:Answer received: !yro37
DEBUG:py4j.clientserver:Command to send: c
o37
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.access.key
DEBUG:py4j.clientserver:Command to send: c
o37
_2
e

DEBUG:py4j.clientserver:Answer received: !ysminioadmin
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i18
e

DEBUG:py4j.clientserver:Answer received: !yro38
DEBUG:py4j.clientserver:Command to send: c
o38
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.serializer.objectStreamReset
DEBUG:py4j.clientserver:Command to send: c
o38
_2
e

DEBUG:py4j.clientserver:Answer received: !ys100
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i19
e

DEBUG:py4j.clientserver:Answer received: !yro39
DEBUG:py4j.clientserver:Command to send: c
o39
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.master
DEBUG:py4j.clientserver:Command to send: c
o39
_2
e

DEBUG:py4j.clientserver:Answer received: !yslocal[*]
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i20
e

DEBUG:py4j.clientserver:Answer received: !yro40
DEBUG:py4j.clientserver:Command to send: c
o40
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.sql.catalog.iceberg_catalog.type
DEBUG:py4j.clientserver:Command to send: c
o40
_2
e

DEBUG:py4j.clientserver:Answer received: !yshadoop
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i21
e

DEBUG:py4j.clientserver:Answer received: !yro41
DEBUG:py4j.clientserver:Command to send: c
o41
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.sql.catalog.iceberg_catalog.io-impl
DEBUG:py4j.clientserver:Command to send: c
o41
_2
e

DEBUG:py4j.clientserver:Answer received: !ysorg.apache.iceberg.aws.s3.S3FileIO
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i22
e

DEBUG:py4j.clientserver:Answer received: !yro42
DEBUG:py4j.clientserver:Command to send: c
o42
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.submit.deployMode
DEBUG:py4j.clientserver:Command to send: c
o42
_2
e

DEBUG:py4j.clientserver:Answer received: !ysclient
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i23
e

DEBUG:py4j.clientserver:Answer received: !yro43
DEBUG:py4j.clientserver:Command to send: c
o43
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.sql.adaptive.enabled
DEBUG:py4j.clientserver:Command to send: c
o43
_2
e

DEBUG:py4j.clientserver:Answer received: !ysfalse
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i24
e

DEBUG:py4j.clientserver:Answer received: !yro44
DEBUG:py4j.clientserver:Command to send: c
o44
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.ui.showConsoleProgress
DEBUG:py4j.clientserver:Command to send: c
o44
_2
e

DEBUG:py4j.clientserver:Answer received: !ystrue
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: a
g
o19
i25
e

DEBUG:py4j.clientserver:Answer received: !yro45
DEBUG:py4j.clientserver:Command to send: c
o45
_1
e

DEBUG:py4j.clientserver:Answer received: !ysspark.hadoop.fs.s3a.secret.key
DEBUG:py4j.clientserver:Command to send: c
o45
_2
e

DEBUG:py4j.clientserver:Answer received: !ysminioadmin
DEBUG:py4j.clientserver:Command to send: a
e
o19
e

DEBUG:py4j.clientserver:Answer received: !yi26
DEBUG:py4j.clientserver:Command to send: r
u
JavaSparkContext
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.java.JavaSparkContext
DEBUG:py4j.clientserver:Command to send: i
org.apache.spark.api.java.JavaSparkContext
ro0
e

DEBUG:py4j.clientserver:Command to send: A
8db796b1b48f0b07676944df940a01850b4373ef0aac66f1b3cba4831e37bc68

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o1
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o2
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o3
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o4
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o5
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o6
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o7
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o8
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o9
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o10
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o11
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o12
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o13
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o14
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o15
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o16
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o17
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o18
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o19
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !yro46
DEBUG:py4j.clientserver:Command to send: c
o46
sc
e

DEBUG:py4j.clientserver:Answer received: !yro47
DEBUG:py4j.clientserver:Command to send: c
o47
conf
e

DEBUG:py4j.clientserver:Answer received: !yro48
DEBUG:py4j.clientserver:Command to send: r
u
PythonAccumulatorV2
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonAccumulatorV2
DEBUG:py4j.clientserver:Command to send: i
org.apache.spark.api.python.PythonAccumulatorV2
s127.0.0.1
i49071
s8db796b1b48f0b07676944df940a01850b4373ef0aac66f1b3cba4831e37bc68
e

DEBUG:py4j.clientserver:Answer received: !yro49
DEBUG:py4j.clientserver:Command to send: c
o46
sc
e

DEBUG:py4j.clientserver:Answer received: !yro50
DEBUG:py4j.clientserver:Command to send: c
o50
register
ro49
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
ro46
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
ro46
e

DEBUG:py4j.clientserver:Answer received: !yL15
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
getSparkBufferSize
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
getSparkBufferSize
ro46
e

DEBUG:py4j.clientserver:Answer received: !yi65536
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: c
o48
get
sspark.submit.pyFiles
s
e

DEBUG:py4j.clientserver:Answer received: !ys/home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-common-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.iceberg_iceberg-aws-bundle-1.9.1.jar,/home/fastnnefarious/.ivy2/jars/software.amazon.awssdk_bundle-2.24.6.jar,/home/fastnnefarious/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-protobuf_3_25-1.3.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.3.0.jar,/home/fastnnefarious/.ivy2/jars/com.google.guava_guava-27.0-jre.jar,/home/fastnnefarious/.ivy2/jars/commons-cli_commons-cli-1.5.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,/home/fastnnefarious/.ivy2/jars/commons-codec_commons-codec-1.15.jar,/home/fastnnefarious/.ivy2/jars/commons-io_commons-io-2.16.1.jar,/home/fastnnefarious/.ivy2/jars/commons-net_commons-net-3.9.0.jar,/home/fastnnefarious/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar,/home/fastnnefarious/.ivy2/jars/javax.servlet_javax.servlet-api-3.1.0.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-server-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-servlet-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-webapp-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-core-1.19.4.jar,/home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-servlet-1.19.4.jar,/home/fastnnefarious/.ivy2/jars/com.github.pjfanning_jersey-json-1.22.0.jar,/home/fastnnefarious/.ivy2/jars/org.codehaus.jettison_jettison-1.5.4.jar,/home/fastnnefarious/.ivy2/jars/com.sun.jersey_jersey-server-1.19.4.jar,/home/fastnnefarious/.ivy2/jars/ch.qos.reload4j_reload4j-1.2.22.jar,/home/fastnnefarious/.ivy2/jars/commons-beanutils_commons-beanutils-1.9.4.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-configuration2-2.10.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-lang3-3.12.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-text-1.10.0.jar,/home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-api-1.7.36.jar,/home/fastnnefarious/.ivy2/jars/org.slf4j_slf4j-reload4j-1.7.36.jar,/home/fastnnefarious/.ivy2/jars/org.apache.avro_avro-1.9.2.jar,/home/fastnnefarious/.ivy2/jars/com.google.re2j_re2j-1.1.jar,/home/fastnnefarious/.ivy2/jars/com.google.code.gson_gson-2.9.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.hadoop_hadoop-auth-3.4.1.jar,/home/fastnnefarious/.ivy2/jars/com.jcraft_jsch-0.1.55.jar,/home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-client-5.2.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-recipes-5.2.0.jar,/home/fastnnefarious/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar,/home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-3.8.4.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-handler-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-epoll-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.dropwizard.metrics_metrics-core-3.2.4.jar,/home/fastnnefarious/.ivy2/jars/org.apache.commons_commons-compress-1.26.1.jar,/home/fastnnefarious/.ivy2/jars/org.bouncycastle_bcprov-jdk18on-1.78.1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-core-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.12.7.1.jar,/home/fastnnefarious/.ivy2/jars/org.codehaus.woodstox_stax2-api-4.2.1.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.woodstox_woodstox-core-5.4.0.jar,/home/fastnnefarious/.ivy2/jars/dnsjava_dnsjava-3.6.1.jar,/home/fastnnefarious/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.4.jar,/home/fastnnefarious/.ivy2/jars/com.google.guava_failureaccess-1.0.jar,/home/fastnnefarious/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/fastnnefarious/.ivy2/jars/org.checkerframework_checker-qual-2.5.2.jar,/home/fastnnefarious/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,/home/fastnnefarious/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.17.jar,/home/fastnnefarious/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,/home/fastnnefarious/.ivy2/jars/commons-logging_commons-logging-1.2.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-http-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-io-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-security-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/org.eclipse.jetty_jetty-xml-9.4.53.v20231009.jar,/home/fastnnefarious/.ivy2/jars/javax.ws.rs_jsr311-api-1.1.1.jar,/home/fastnnefarious/.ivy2/jars/com.sun.xml.bind_jaxb-impl-2.2.3-1.jar,/home/fastnnefarious/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.12.7.jar,/home/fastnnefarious/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.12.7.jar,/home/fastnnefarious/.ivy2/jars/com.nimbusds_nimbus-jose-jwt-9.37.2.jar,/home/fastnnefarious/.ivy2/jars/org.apache.curator_curator-framework-5.2.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-util-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar,/home/fastnnefarious/.ivy2/jars/org.apache.zookeeper_zookeeper-jute-3.8.4.jar,/home/fastnnefarious/.ivy2/jars/org.apache.yetus_audience-annotations-0.12.0.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-pkix-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-asn1-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-util-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerby-config-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/org.apache.kerby_kerb-crypto-2.0.3.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-common-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-resolver-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-buffer-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-native-unix-common-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-codec-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/io.netty_netty-transport-classes-epoll-4.1.100.Final.jar,/home/fastnnefarious/.ivy2/jars/jakarta.activation_jakarta.activation-api-1.2.1.jar,/home/fastnnefarious/.ivy2/jars/javax.servlet.jsp_jsp-api-2.1.jar
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.SparkFiles
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.SparkFiles
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/userFiles-9e7e2b37-6290-4caa-a1a7-1be6654b4c37
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.util
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.util.Utils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.util.Utils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.util.Utils
getLocalDir
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
o46
sc
e

DEBUG:py4j.clientserver:Answer received: !yro51
DEBUG:py4j.clientserver:Command to send: c
o51
conf
e

DEBUG:py4j.clientserver:Answer received: !yro52
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.util.Utils
getLocalDir
ro52
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.util
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.util.Utils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.util.Utils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.util.Utils
createTempDir
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.util.Utils
createTempDir
s/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9
spyspark
e

DEBUG:py4j.clientserver:Answer received: !yro53
DEBUG:py4j.clientserver:Command to send: c
o53
getAbsolutePath
e

DEBUG:py4j.clientserver:Answer received: !ys/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/pyspark-bf9399da-b7e2-4356-802c-7d1afe92537a
DEBUG:py4j.clientserver:Command to send: c
o48
get
sspark.python.profile
sfalse
e

DEBUG:py4j.clientserver:Answer received: !ysfalse
DEBUG:py4j.clientserver:Command to send: c
o48
get
sspark.python.profile.memory
sfalse
e

DEBUG:py4j.clientserver:Answer received: !ysfalse
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getDefaultSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getDefaultSession
e

DEBUG:py4j.clientserver:Answer received: !yro54
DEBUG:py4j.clientserver:Command to send: c
o54
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: c
o46
sc
e

DEBUG:py4j.clientserver:Answer received: !yro55
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao56
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.app.name
sNASA_NEO_Silver_Data
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.jars.packages
sorg.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.1,org.apache.hadoop:hadoop-aws:3.4.1,org.apache.hadoop:hadoop-common:3.4.1,org.apache.iceberg:iceberg-aws-bundle:1.9.1
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.sql.extensions
sorg.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.sql.catalog.iceberg_catalog
sorg.apache.iceberg.spark.SparkCatalog
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.sql.catalog.iceberg_catalog.type
shadoop
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.sql.catalog.iceberg_catalog.warehouse
ss3a://neo
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.sql.catalog.iceberg_catalog.io-impl
sorg.apache.iceberg.aws.s3.S3FileIO
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.endpoint
shttp://localhost:9000
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.access.key
sminioadmin
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.secret.key
sminioadmin
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.path.style.access
strue
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.connection.ssl.enabled
sfalse
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.impl
sorg.apache.hadoop.fs.s3a.S3AFileSystem
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.hadoop.fs.s3a.aws.credentials.provider
sorg.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.sql.adaptive.enabled
sfalse
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: c
o56
put
sspark.serializer
sorg.apache.spark.serializer.KryoSerializer
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: i
org.apache.spark.sql.SparkSession
ro55
ro56
e

DEBUG:py4j.clientserver:Answer received: !yro57
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
setDefaultSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
setDefaultSession
ro57
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro57
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toArray
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo58
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toArray
ro58
e

DEBUG:py4j.clientserver:Answer received: !yto59
DEBUG:py4j.clientserver:Command to send: c
o57
sql
sSELECT 1
ro59
e

DEBUG:py4j.clientserver:Command to send: m
d
o56
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o58
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !yro60
DEBUG:py4j.clientserver:Command to send: c
o46
setCallSite
scollect at /tmp/ipykernel_117600/572422691.py:249
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o60
collectToPython
e

DEBUG:py4j.clientserver:Answer received: !yto61
DEBUG:py4j.clientserver:Command to send: c
o46
setCallSite
n
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: a
e
o61
e

DEBUG:py4j.clientserver:Answer received: !yi3
DEBUG:py4j.clientserver:Command to send: a
g
o61
i0
e

DEBUG:py4j.clientserver:Answer received: !yi38703
DEBUG:py4j.clientserver:Command to send: a
e
o61
e

DEBUG:py4j.clientserver:Answer received: !yi3
DEBUG:py4j.clientserver:Command to send: a
g
o61
i1
e

DEBUG:py4j.clientserver:Answer received: !ys1f2a798f90acf394a7597ae1f0d17164d707068d99029787d46aeaa15606a3f6
DEBUG:__main__:Spark session basic functionality validated
INFO:__main__:Successfully created Spark session: NASA_NEO_Silver_Data
INFO:src.transformations:Starting JSON to DataFrame transformation
DEBUG:src.transformations:Input validation passed: 8 date entries
DEBUG:src.transformations:Creating DataFrame from JSON data
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro57
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o46
sc
e

DEBUG:py4j.clientserver:Answer received: !yro62
DEBUG:py4j.clientserver:Command to send: c
o62
defaultParallelism
e

DEBUG:py4j.clientserver:Answer received: !yi8
DEBUG:py4j.clientserver:Command to send: r
u
PythonRDD
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonRDD
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonRDD
readRDDFromFile
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonRDD
readRDDFromFile
ro46
s/tmp/spark-43487010-1dbe-448f-8943-a8035d528fe9/pyspark-bf9399da-b7e2-4356-802c-7d1afe92537a/tmpway24rlo
i8
e

DEBUG:py4j.clientserver:Answer received: !yro63
DEBUG:py4j.clientserver:Command to send: c
o63
id
e

DEBUG:py4j.clientserver:Answer received: !yi3
DEBUG:py4j.clientserver:Command to send: r
u
SerDeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.SerDeUtil
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.SerDeUtil
toJavaArray
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
o63
rdd
e

DEBUG:py4j.clientserver:Command to send: m
d
o61
e

DEBUG:py4j.clientserver:Answer received: !yro64
DEBUG:py4j.clientserver:Command to send: c
o64
isBarrier
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
SerDeUtil
rj
e

DEBUG:py4j.clientserver:Command to send: m
d
o0
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o20
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.SerDeUtil
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.SerDeUtil
pythonToJava
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o21
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o22
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o23
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
getBroadcastThreshold
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: m
d
o24
e

DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
getBroadcastThreshold
ro46
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o25
e

DEBUG:py4j.clientserver:Answer received: !yL1048576
DEBUG:py4j.clientserver:Command to send: r
u
SimplePythonFunction
rj
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o26
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o27
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o28
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o29
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o30
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o31
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o32
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o33
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o34
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o35
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o36
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.SimplePythonFunction
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o37
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !yao65
DEBUG:py4j.clientserver:Command to send: m
d
o38
e

DEBUG:py4j.clientserver:Command to send: c
o65
put
sPYTHONHASHSEED
s0
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o39
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o40
e

DEBUG:py4j.clientserver:Answer received: !ylo66
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.1.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o41
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o42
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o43
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.hadoop_hadoop-aws-3.4.1.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o44
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.hadoop_hadoop-common-3.4.1.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o45
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.iceberg_iceberg-aws-bundle-1.9.1.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o47
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
ssoftware.amazon.awssdk_bundle-2.24.6.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o50
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o51
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.hadoop.thirdparty_hadoop-shaded-protobuf_3_25-1.3.0.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o52
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.hadoop_hadoop-annotations-3.4.1.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o53
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.hadoop.thirdparty_hadoop-shaded-guava-1.3.0.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o54
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.guava_guava-27.0-jre.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o55
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-cli_commons-cli-1.5.0.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: m
d
o59
e

DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.commons_commons-math3-3.6.1.jar
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o60
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.httpcomponents_httpclient-4.5.13.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-codec_commons-codec-1.15.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-io_commons-io-2.16.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-net_commons-net-3.9.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-collections_commons-collections-3.2.2.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sjavax.servlet_javax.servlet-api-3.1.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-server-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-util-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-servlet-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-webapp-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.sun.jersey_jersey-core-1.19.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.sun.jersey_jersey-servlet-1.19.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.github.pjfanning_jersey-json-1.22.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.codehaus.jettison_jettison-1.5.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.sun.jersey_jersey-server-1.19.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sch.qos.reload4j_reload4j-1.2.22.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-beanutils_commons-beanutils-1.9.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.commons_commons-configuration2-2.10.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.commons_commons-lang3-3.12.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.commons_commons-text-1.10.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.slf4j_slf4j-api-1.7.36.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.slf4j_slf4j-reload4j-1.7.36.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.avro_avro-1.9.2.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.re2j_re2j-1.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.code.gson_gson-2.9.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.hadoop_hadoop-auth-3.4.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.jcraft_jsch-0.1.55.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.curator_curator-client-5.2.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.curator_curator-recipes-5.2.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.code.findbugs_jsr305-3.0.2.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.zookeeper_zookeeper-3.8.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-handler-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-transport-native-epoll-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.dropwizard.metrics_metrics-core-3.2.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.commons_commons-compress-1.26.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.bouncycastle_bcprov-jdk18on-1.78.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerb-core-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.fasterxml.jackson.core_jackson-databind-2.12.7.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.codehaus.woodstox_stax2-api-4.2.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.fasterxml.woodstox_woodstox-core-5.4.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sdnsjava_dnsjava-3.6.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.xerial.snappy_snappy-java-1.1.10.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.guava_failureaccess-1.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.checkerframework_checker-qual-2.5.2.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.google.j2objc_j2objc-annotations-1.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.codehaus.mojo_animal-sniffer-annotations-1.17.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.httpcomponents_httpcore-4.4.13.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scommons-logging_commons-logging-1.2.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-http-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-io-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-security-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-util-ajax-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.eclipse.jetty_jetty-xml-9.4.53.v20231009.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sjavax.ws.rs_jsr311-api-1.1.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.sun.xml.bind_jaxb-impl-2.2.3-1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sjavax.xml.bind_jaxb-api-2.2.11.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.fasterxml.jackson.core_jackson-core-2.12.7.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.fasterxml.jackson.core_jackson-annotations-2.12.7.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.nimbusds_nimbus-jose-jwt-9.37.2.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.curator_curator-framework-5.2.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerb-util-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
scom.github.stephenc.jcip_jcip-annotations-1.0-1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.zookeeper_zookeeper-jute-3.8.4.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.yetus_audience-annotations-0.12.0.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerby-pkix-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerby-asn1-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerby-util-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerby-config-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sorg.apache.kerby_kerb-crypto-2.0.3.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-common-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-resolver-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-buffer-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-transport-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-transport-native-unix-common-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-codec-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sio.netty_netty-transport-classes-epoll-4.1.100.Final.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sjakarta.activation_jakarta.activation-api-1.2.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o66
add
sjavax.servlet.jsp_jsp-api-2.1.jar
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo67
DEBUG:py4j.clientserver:Command to send: i
org.apache.spark.api.python.SimplePythonFunction
jgAWVagUAAAAAAAAojB9weXNwYXJrLmNsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwJLAEsASwJLBUsTQy6VAZcAdAEAAAAAAAAAAHQDAAAAAAAAAACJAqsBAAAAAAAAfAGrAgAAAAAAAFMAlE6FlIwDbWFwlIwVZmFpbF9vbl9zdG9waXRlcmF0aW9ulIaUjAFflIwIaXRlcmF0b3KUhpSMcS9ob21lL2Zhc3RubmVmYXJpb3VzL1Byb2plY3RzL1B5Y2hhcm1Qcm9qZWN0cy9uYXNhX25lb19waXBlbGluZS8udmVudi9saWIvcHl0aG9uMy4xMi9zaXRlLXBhY2thZ2VzL3B5c3BhcmsvcmRkLnB5lIwEZnVuY5SMFVJERC5tYXAuPGxvY2Fscz4uZnVuY5RN8QJDFviAANwTFtQXLKhR0xcvsBjTEzrQDDqUQwCUjAFmlIWUKXSUUpR9lCiMC19fcGFja2FnZV9flIwHcHlzcGFya5SMCF9fbmFtZV9flIwLcHlzcGFyay5yZGSUjAhfX2ZpbGVfX5SMcS9ob21lL2Zhc3RubmVmYXJpb3VzL1Byb2plY3RzL1B5Y2hhcm1Qcm9qZWN0cy9uYXNhX25lb19waXBlbGluZS8udmVudi9saWIvcHl0aG9uMy4xMi9zaXRlLXBhY2thZ2VzL3B5c3BhcmsvcmRkLnB5lHVOTmgAjBBfbWFrZV9lbXB0eV9jZWxslJOUKVKUhZR0lFKUjCRweXNwYXJrLmNsb3VkcGlja2xlLmNsb3VkcGlja2xlX2Zhc3SUjBJfZnVuY3Rpb25fc2V0c3RhdGWUk5RoJX2UfZQoaBxoEYwMX19xdWFsbmFtZV9flGgSjA9fX2Fubm90YXRpb25zX1+UfZQoaA2MCGJ1aWx0aW5zlIwDaW50lJOUaA6MCV9vcGVyYXRvcpSMB2dldGl0ZW2Uk5SMBnR5cGluZ5SMCEl0ZXJhYmxllJOUjAhidWlsdGluc5SMB2dldGF0dHKUk5RoAIwJc3ViaW1wb3J0lJOUaB2FlFKUjAFUlIaUUpSGlFKUjAZyZXR1cm6UaDNoNmg5aD2MAVWUhpRSlIaUUpR1jA5fX2t3ZGVmYXVsdHNfX5ROjAxfX2RlZmF1bHRzX1+UTowKX19tb2R1bGVfX5RoHYwHX19kb2NfX5ROjAtfX2Nsb3N1cmVfX5RoAIwKX21ha2VfY2VsbJSTlGgCKGgHKEsBSwBLAEsBSwFLE0MGlwB8AFMAlGgJKYwBeJSFlGgQjAg8bGFtYmRhPpSMIlJERC5fcmVzZXJpYWxpemUuPGxvY2Fscz4uPGxhbWJkYT6UTSUFQwaAAKBhgACUaBQpKXSUUpRoGU5OTnSUUpRoKGhZfZR9lChoHGhTaCtoVGgsfZRoSU5oSk5oS2gdaExOaE1OjBdfY2xvdWRwaWNrbGVfc3VibW9kdWxlc5RdlIwLX19nbG9iYWxzX1+UfZR1hpSGUjCFlFKUhZRoXV2UaF99lGgLjAxweXNwYXJrLnV0aWyUaAuTlHN1hpSGUjBOjBNweXNwYXJrLnNlcmlhbGl6ZXJzlIwRQmF0Y2hlZFNlcmlhbGl6ZXKUk5QpgZR9lCiMCnNlcmlhbGl6ZXKUaGqMFUNsb3VkUGlja2xlU2VyaWFsaXplcpSTlCmBlIwJYmF0Y2hTaXpllEsBdWJoaowVQXV0b0JhdGNoZWRTZXJpYWxpemVylJOUKYGUfZQoaG9ocSmBlGhzSwCMCGJlc3RTaXpllEoAAAEAdWJ0lC4=
ro65
ro66
spython3
s3.12
ro67
ro49
e

DEBUG:py4j.clientserver:Answer received: !yro68
DEBUG:py4j.clientserver:Command to send: r
u
PythonRDD
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonRDD
DEBUG:py4j.clientserver:Command to send: c
o63
rdd
e

DEBUG:py4j.clientserver:Answer received: !yro69
DEBUG:py4j.clientserver:Command to send: i
org.apache.spark.api.python.PythonRDD
ro69
ro68
bTrue
bFalse
e

DEBUG:py4j.clientserver:Answer received: !yro70
DEBUG:py4j.clientserver:Command to send: c
o70
asJavaRDD
e

DEBUG:py4j.clientserver:Answer received: !yro71
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.SerDeUtil
pythonToJava
ro71
bTrue
e

DEBUG:py4j.clientserver:Answer received: !yro72
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.SerDeUtil
toJavaArray
ro72
e

DEBUG:py4j.clientserver:Answer received: !yro73
DEBUG:py4j.clientserver:Command to send: c
o73
rdd
e

DEBUG:py4j.clientserver:Answer received: !yro74
DEBUG:py4j.clientserver:Command to send: c
o57
applySchemaToPythonRDD
ro74
s{"fields":[{"metadata":{},"name":"element_count","nullable":true,"type":"integer"},{"metadata":{},"name":"near_earth_objects","nullable":true,"type":{"keyType":"string","type":"map","valueContainsNull":true,"valueType":{"containsNull":true,"elementType":{"fields":[{"metadata":{},"name":"absolute_magnitude_h","nullable":true,"type":"double"},{"metadata":{},"name":"close_approach_data","nullable":true,"type":{"containsNull":true,"elementType":{"fields":[{"metadata":{},"name":"close_approach_date","nullable":true,"type":"string"},{"metadata":{},"name":"close_approach_date_full","nullable":true,"type":"string"},{"metadata":{},"name":"epoch_date_close_approach","nullable":true,"type":"long"},{"metadata":{},"name":"miss_distance","nullable":true,"type":{"fields":[{"metadata":{},"name":"astronomical","nullable":true,"type":"string"},{"metadata":{},"name":"kilometers","nullable":true,"type":"string"},{"metadata":{},"name":"lunar","nullable":true,"type":"string"},{"metadata":{},"name":"miles","nullable":true,"type":"string"}],"type":"struct"}},{"metadata":{},"name":"orbiting_body","nullable":true,"type":"string"},{"metadata":{},"name":"relative_velocity","nullable":true,"type":{"fields":[{"metadata":{},"name":"kilometers_per_hour","nullable":true,"type":"string"},{"metadata":{},"name":"kilometers_per_second","nullable":true,"type":"string"},{"metadata":{},"name":"miles_per_hour","nullable":true,"type":"string"}],"type":"struct"}}],"type":"struct"},"type":"array"}},{"metadata":{},"name":"estimated_diameter","nullable":true,"type":{"fields":[{"metadata":{},"name":"feet","nullable":true,"type":{"fields":[{"metadata":{},"name":"estimated_diameter_min","nullable":true,"type":"double"},{"metadata":{},"name":"estimated_diameter_max","nullable":true,"type":"double"}],"type":"struct"}},{"metadata":{},"name":"kilometers","nullable":true,"type":{"fields":[{"metadata":{},"name":"estimated_diameter_min","nullable":true,"type":"double"},{"metadata":{},"name":"estimated_diameter_max","nullable":true,"type":"double"}],"type":"struct"}},{"metadata":{},"name":"meters","nullable":true,"type":{"fields":[{"metadata":{},"name":"estimated_diameter_min","nullable":true,"type":"double"},{"metadata":{},"name":"estimated_diameter_max","nullable":true,"type":"double"}],"type":"struct"}},{"metadata":{},"name":"miles","nullable":true,"type":{"fields":[{"metadata":{},"name":"estimated_diameter_min","nullable":true,"type":"double"},{"metadata":{},"name":"estimated_diameter_max","nullable":true,"type":"double"}],"type":"struct"}}],"type":"struct"}},{"metadata":{},"name":"id","nullable":true,"type":"string"},{"metadata":{},"name":"is_potentially_hazardous_asteroid","nullable":true,"type":"boolean"},{"metadata":{},"name":"is_sentry_object","nullable":true,"type":"boolean"},{"metadata":{},"name":"name","nullable":true,"type":"string"},{"metadata":{},"name":"nasa_jpl_url","nullable":true,"type":"string"},{"metadata":{},"name":"neo_reference_id","nullable":true,"type":"string"},{"metadata":{},"name":"sentry_data","nullable":true,"type":"string"}],"type":"struct"},"type":"array"}}}],"type":"struct"}
e

DEBUG:py4j.clientserver:Answer received: !yro75
DEBUG:src.transformations:Exploding date entries from near_earth_objects map
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
expr
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
expr
smap_entries(near_earth_objects)
e

DEBUG:py4j.clientserver:Answer received: !yro76
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
explode
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
explode
ro76
e

DEBUG:py4j.clientserver:Answer received: !yro77
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo78
DEBUG:py4j.clientserver:Command to send: c
o78
add
ro77
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro78
e

DEBUG:py4j.clientserver:Answer received: !yro79
DEBUG:py4j.clientserver:Command to send: c
o75
select
ro79
e

DEBUG:py4j.clientserver:Answer received: !yro80
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo81
DEBUG:py4j.clientserver:Command to send: c
o81
add
sdate_entry
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro81
e

DEBUG:py4j.clientserver:Answer received: !yro82
DEBUG:py4j.clientserver:Command to send: c
o80
toDF
ro82
e

DEBUG:py4j.clientserver:Answer received: !yro83
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdate_entry.key
e

DEBUG:py4j.clientserver:Answer received: !yro84
DEBUG:py4j.clientserver:Command to send: c
o84
as
sobservation_date
e

DEBUG:py4j.clientserver:Answer received: !yro85
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdate_entry.value
e

DEBUG:py4j.clientserver:Answer received: !yro86
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
explode
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
explode
ro86
e

DEBUG:py4j.clientserver:Answer received: !yro87
DEBUG:py4j.clientserver:Command to send: c
o87
as
sasteroid
e

DEBUG:py4j.clientserver:Answer received: !yro88
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo89
DEBUG:py4j.clientserver:Command to send: c
o89
add
ro85
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o89
add
ro88
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro89
e

DEBUG:py4j.clientserver:Answer received: !yro90
DEBUG:py4j.clientserver:Command to send: c
o83
select
ro90
e

DEBUG:py4j.clientserver:Answer received: !yro91
DEBUG:src.transformations:Extracting asteroid properties
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sobservation_date
e

DEBUG:py4j.clientserver:Answer received: !yro92
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.id
e

DEBUG:py4j.clientserver:Answer received: !yro93
DEBUG:py4j.clientserver:Command to send: c
o93
as
sasteroid_id
e

DEBUG:py4j.clientserver:Answer received: !yro94
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.neo_reference_id
e

DEBUG:py4j.clientserver:Answer received: !yro95
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.name
e

DEBUG:py4j.clientserver:Answer received: !yro96
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.nasa_jpl_url
e

DEBUG:py4j.clientserver:Answer received: !yro97
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.absolute_magnitude_h
e

DEBUG:py4j.clientserver:Answer received: !yro98
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.kilometers.estimated_diameter_min
e

DEBUG:py4j.clientserver:Answer received: !yro99
DEBUG:py4j.clientserver:Command to send: c
o99
as
sdiameter_min_km
e

DEBUG:py4j.clientserver:Answer received: !yro100
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.kilometers.estimated_diameter_max
e

DEBUG:py4j.clientserver:Answer received: !yro101
DEBUG:py4j.clientserver:Command to send: c
o101
as
sdiameter_max_km
e

DEBUG:py4j.clientserver:Answer received: !yro102
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.meters.estimated_diameter_min
e

DEBUG:py4j.clientserver:Answer received: !yro103
DEBUG:py4j.clientserver:Command to send: c
o103
as
sdiameter_min_m
e

DEBUG:py4j.clientserver:Answer received: !yro104
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.meters.estimated_diameter_max
e

DEBUG:py4j.clientserver:Answer received: !yro105
DEBUG:py4j.clientserver:Command to send: c
o105
as
sdiameter_max_m
e

DEBUG:py4j.clientserver:Answer received: !yro106
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.miles.estimated_diameter_min
e

DEBUG:py4j.clientserver:Answer received: !yro107
DEBUG:py4j.clientserver:Command to send: c
o107
as
sdiameter_min_mi
e

DEBUG:py4j.clientserver:Answer received: !yro108
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.miles.estimated_diameter_max
e

DEBUG:py4j.clientserver:Answer received: !yro109
DEBUG:py4j.clientserver:Command to send: c
o109
as
sdiameter_max_mi
e

DEBUG:py4j.clientserver:Answer received: !yro110
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.feet.estimated_diameter_min
e

DEBUG:py4j.clientserver:Answer received: !yro111
DEBUG:py4j.clientserver:Command to send: c
o111
as
sdiameter_min_ft
e

DEBUG:py4j.clientserver:Answer received: !yro112
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.estimated_diameter.feet.estimated_diameter_max
e

DEBUG:py4j.clientserver:Answer received: !yro113
DEBUG:py4j.clientserver:Command to send: c
o113
as
sdiameter_max_ft
e

DEBUG:py4j.clientserver:Answer received: !yro114
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.is_potentially_hazardous_asteroid
e

DEBUG:py4j.clientserver:Answer received: !yro115
DEBUG:py4j.clientserver:Command to send: c
o115
as
sis_potentially_hazardous
e

DEBUG:py4j.clientserver:Answer received: !yro116
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.is_sentry_object
e

DEBUG:py4j.clientserver:Answer received: !yro117
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid.close_approach_data
e

DEBUG:py4j.clientserver:Answer received: !yro118
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
explode
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
explode
ro118
e

DEBUG:py4j.clientserver:Answer received: !yro119
DEBUG:py4j.clientserver:Command to send: c
o119
as
sapproach
e

DEBUG:py4j.clientserver:Answer received: !yro120
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo121
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro92
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro94
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro95
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro96
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro97
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro98
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro100
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro102
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro104
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro106
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro108
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro110
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro112
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro114
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro116
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro117
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o121
add
ro120
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro121
e

DEBUG:py4j.clientserver:Answer received: !yro122
DEBUG:py4j.clientserver:Command to send: c
o91
select
ro122
e

DEBUG:py4j.clientserver:Answer received: !yro123
DEBUG:src.transformations:Extracting close approach data
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sobservation_date
e

DEBUG:py4j.clientserver:Answer received: !yro124
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sasteroid_id
e

DEBUG:py4j.clientserver:Answer received: !yro125
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sneo_reference_id
e

DEBUG:py4j.clientserver:Answer received: !yro126
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sname
e

DEBUG:py4j.clientserver:Answer received: !yro127
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
snasa_jpl_url
e

DEBUG:py4j.clientserver:Answer received: !yro128
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sabsolute_magnitude_h
e

DEBUG:py4j.clientserver:Answer received: !yro129
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_min_km
e

DEBUG:py4j.clientserver:Answer received: !yro130
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_max_km
e

DEBUG:py4j.clientserver:Answer received: !yro131
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_min_m
e

DEBUG:py4j.clientserver:Answer received: !yro132
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_max_m
e

DEBUG:py4j.clientserver:Answer received: !yro133
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_min_mi
e

DEBUG:py4j.clientserver:Answer received: !yro134
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_max_mi
e

DEBUG:py4j.clientserver:Answer received: !yro135
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_min_ft
e

DEBUG:py4j.clientserver:Answer received: !yro136
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sdiameter_max_ft
e

DEBUG:py4j.clientserver:Answer received: !yro137
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sis_potentially_hazardous
e

DEBUG:py4j.clientserver:Answer received: !yro138
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sis_sentry_object
e

DEBUG:py4j.clientserver:Answer received: !yro139
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.close_approach_date
e

DEBUG:py4j.clientserver:Answer received: !yro140
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.close_approach_date_full
e

DEBUG:py4j.clientserver:Answer received: !yro141
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.epoch_date_close_approach
e

DEBUG:py4j.clientserver:Answer received: !yro142
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.relative_velocity.kilometers_per_second
e

DEBUG:py4j.clientserver:Answer received: !yro143
DEBUG:py4j.clientserver:Command to send: c
o143
as
svelocity_kps
e

DEBUG:py4j.clientserver:Answer received: !yro144
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.relative_velocity.kilometers_per_hour
e

DEBUG:py4j.clientserver:Answer received: !yro145
DEBUG:py4j.clientserver:Command to send: c
o145
as
svelocity_kph
e

DEBUG:py4j.clientserver:Answer received: !yro146
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.relative_velocity.miles_per_hour
e

DEBUG:py4j.clientserver:Answer received: !yro147
DEBUG:py4j.clientserver:Command to send: c
o147
as
svelocity_mph
e

DEBUG:py4j.clientserver:Answer received: !yro148
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.miss_distance.astronomical
e

DEBUG:py4j.clientserver:Answer received: !yro149
DEBUG:py4j.clientserver:Command to send: c
o149
as
smiss_distance_au
e

DEBUG:py4j.clientserver:Answer received: !yro150
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.miss_distance.lunar
e

DEBUG:py4j.clientserver:Answer received: !yro151
DEBUG:py4j.clientserver:Command to send: c
o151
as
smiss_distance_ld
e

DEBUG:py4j.clientserver:Answer received: !yro152
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.miss_distance.kilometers
e

DEBUG:py4j.clientserver:Answer received: !yro153
DEBUG:py4j.clientserver:Command to send: c
o153
as
smiss_distance_km
e

DEBUG:py4j.clientserver:Answer received: !yro154
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.miss_distance.miles
e

DEBUG:py4j.clientserver:Answer received: !yro155
DEBUG:py4j.clientserver:Command to send: c
o155
as
smiss_distance_mi
e

DEBUG:py4j.clientserver:Answer received: !yro156
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sapproach.orbiting_body
e

DEBUG:py4j.clientserver:Answer received: !yro157
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo158
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro124
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro125
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro126
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro127
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro128
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro129
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro130
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro131
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro132
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro133
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro134
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro135
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro136
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro137
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro138
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro139
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro140
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro141
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro142
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro144
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro146
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro148
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro150
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro152
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro154
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro156
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
o158
add
ro157
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro158
e

DEBUG:py4j.clientserver:Answer received: !yro159
DEBUG:py4j.clientserver:Command to send: c
o123
select
ro159
e

DEBUG:py4j.clientserver:Answer received: !yro160
DEBUG:src.transformations:Converting data types
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sobservation_date
e

DEBUG:py4j.clientserver:Answer received: !yro161
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
to_date
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
to_date
ro161
e

DEBUG:py4j.clientserver:Answer received: !yro162
DEBUG:py4j.clientserver:Command to send: c
o160
withColumn
sobservation_date
ro162
e

DEBUG:py4j.clientserver:Answer received: !yro163
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
sclose_approach_date
e

DEBUG:py4j.clientserver:Answer received: !yro164
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
to_date
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
to_date
ro164
e

DEBUG:py4j.clientserver:Answer received: !yro165
DEBUG:py4j.clientserver:Command to send: c
o163
withColumn
sclose_approach_date
ro165
e

DEBUG:py4j.clientserver:Answer received: !yro166
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
svelocity_kps
e

DEBUG:py4j.clientserver:Answer received: !yro167
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro168
DEBUG:py4j.clientserver:Command to send: c
o168
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro169
DEBUG:py4j.clientserver:Command to send: c
o169
get
e

DEBUG:py4j.clientserver:Answer received: !yro170
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro171
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao172
DEBUG:py4j.clientserver:Command to send: c
o171
applyModifiableSettings
ro170
ro172
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro173
DEBUG:py4j.clientserver:Command to send: c
o167
cast
ro173
e

DEBUG:py4j.clientserver:Answer received: !yro174
DEBUG:py4j.clientserver:Command to send: c
o166
withColumn
svelocity_kps
ro174
e

DEBUG:py4j.clientserver:Answer received: !yro175
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
svelocity_kph
e

DEBUG:py4j.clientserver:Answer received: !yro176
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro177
DEBUG:py4j.clientserver:Command to send: c
o177
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro178
DEBUG:py4j.clientserver:Command to send: c
o178
get
e

DEBUG:py4j.clientserver:Answer received: !yro179
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro180
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao181
DEBUG:py4j.clientserver:Command to send: c
o180
applyModifiableSettings
ro179
ro181
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro182
DEBUG:py4j.clientserver:Command to send: c
o176
cast
ro182
e

DEBUG:py4j.clientserver:Answer received: !yro183
DEBUG:py4j.clientserver:Command to send: c
o175
withColumn
svelocity_kph
ro183
e

DEBUG:py4j.clientserver:Answer received: !yro184
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
svelocity_mph
e

DEBUG:py4j.clientserver:Answer received: !yro185
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro186
DEBUG:py4j.clientserver:Command to send: c
o186
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro187
DEBUG:py4j.clientserver:Command to send: c
o187
get
e

DEBUG:py4j.clientserver:Answer received: !yro188
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro189
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao190
DEBUG:py4j.clientserver:Command to send: c
o189
applyModifiableSettings
ro188
ro190
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro191
DEBUG:py4j.clientserver:Command to send: c
o185
cast
ro191
e

DEBUG:py4j.clientserver:Answer received: !yro192
DEBUG:py4j.clientserver:Command to send: c
o184
withColumn
svelocity_mph
ro192
e

DEBUG:py4j.clientserver:Answer received: !yro193
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
smiss_distance_au
e

DEBUG:py4j.clientserver:Answer received: !yro194
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro195
DEBUG:py4j.clientserver:Command to send: c
o195
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro196
DEBUG:py4j.clientserver:Command to send: c
o196
get
e

DEBUG:py4j.clientserver:Answer received: !yro197
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro198
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao199
DEBUG:py4j.clientserver:Command to send: c
o198
applyModifiableSettings
ro197
ro199
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro200
DEBUG:py4j.clientserver:Command to send: c
o194
cast
ro200
e

DEBUG:py4j.clientserver:Answer received: !yro201
DEBUG:py4j.clientserver:Command to send: c
o193
withColumn
smiss_distance_au
ro201
e

DEBUG:py4j.clientserver:Answer received: !yro202
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
smiss_distance_ld
e

DEBUG:py4j.clientserver:Answer received: !yro203
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro204
DEBUG:py4j.clientserver:Command to send: c
o204
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro205
DEBUG:py4j.clientserver:Command to send: c
o205
get
e

DEBUG:py4j.clientserver:Answer received: !yro206
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro207
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao208
DEBUG:py4j.clientserver:Command to send: c
o207
applyModifiableSettings
ro206
ro208
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro209
DEBUG:py4j.clientserver:Command to send: c
o203
cast
ro209
e

DEBUG:py4j.clientserver:Answer received: !yro210
DEBUG:py4j.clientserver:Command to send: c
o202
withColumn
smiss_distance_ld
ro210
e

DEBUG:py4j.clientserver:Answer received: !yro211
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
smiss_distance_km
e

DEBUG:py4j.clientserver:Answer received: !yro212
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro213
DEBUG:py4j.clientserver:Command to send: c
o213
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro214
DEBUG:py4j.clientserver:Command to send: c
o214
get
e

DEBUG:py4j.clientserver:Answer received: !yro215
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro216
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao217
DEBUG:py4j.clientserver:Command to send: c
o216
applyModifiableSettings
ro215
ro217
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro218
DEBUG:py4j.clientserver:Command to send: c
o212
cast
ro218
e

DEBUG:py4j.clientserver:Answer received: !yro219
DEBUG:py4j.clientserver:Command to send: c
o211
withColumn
smiss_distance_km
ro219
e

DEBUG:py4j.clientserver:Answer received: !yro220
DEBUG:py4j.clientserver:Command to send: r
u
functions
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.functions
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.functions
col
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.functions
col
smiss_distance_mi
e

DEBUG:py4j.clientserver:Answer received: !yro221
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro222
DEBUG:py4j.clientserver:Command to send: c
o222
isDefined
e

DEBUG:py4j.clientserver:Answer received: !ybtrue
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.sql.SparkSession
getActiveSession
e

DEBUG:py4j.clientserver:Answer received: !yro223
DEBUG:py4j.clientserver:Command to send: c
o223
get
e

DEBUG:py4j.clientserver:Answer received: !yro224
DEBUG:py4j.clientserver:Command to send: r
u
SparkSession$
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.sql.SparkSession$
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.sql.SparkSession$
MODULE$
e

DEBUG:py4j.clientserver:Answer received: !yro225
DEBUG:py4j.clientserver:Command to send: i
java.util.HashMap
e

DEBUG:py4j.clientserver:Answer received: !yao226
DEBUG:py4j.clientserver:Command to send: c
o225
applyModifiableSettings
ro224
ro226
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: c
o57
parseDataType
s"double"
e

DEBUG:py4j.clientserver:Answer received: !yro227
DEBUG:py4j.clientserver:Command to send: c
o221
cast
ro227
e

DEBUG:py4j.clientserver:Answer received: !yro228
DEBUG:py4j.clientserver:Command to send: c
o220
withColumn
smiss_distance_mi
ro228
e

DEBUG:py4j.clientserver:Answer received: !yro229
DEBUG:py4j.clientserver:Command to send: c
o229
count
e

DEBUG:py4j.clientserver:Command to send: m
d
o65
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o66
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o67
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o78
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o81
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o89
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o121
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o158
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o172
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o181
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o190
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o62
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o63
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o64
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o68
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o69
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o70
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o71
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o72
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o73
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o74
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o76
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o77
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o79
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o80
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o82
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o83
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o84
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o85
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o86
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o87
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o88
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o90
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o92
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o93
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o94
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o95
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o96
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o97
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o98
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o99
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o100
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o101
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o102
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o103
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o104
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o105
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o106
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o107
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o108
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o109
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o110
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o111
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o112
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o113
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o114
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o115
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o116
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o117
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o118
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o119
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o120
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o122
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o124
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o125
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o126
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o127
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o128
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o129
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o130
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o131
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o132
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o133
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o134
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o135
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o136
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o137
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o138
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o139
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o140
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o141
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o142
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o143
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o144
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o145
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o146
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o147
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o148
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o149
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o150
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o151
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o152
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o153
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o154
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o155
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o156
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o157
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o159
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o161
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o162
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o163
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o164
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o165
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o166
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o167
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o168
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o169
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o170
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o171
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o173
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o174
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o175
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o176
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o177
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o178
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o179
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o180
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o182
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o183
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o184
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o185
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o186
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o187
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o189
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o191
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o192
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o195
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o199
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o208
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o217
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o226
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !yL122
INFO:src.transformations:Successfully transformed JSON to DataFrame with 122 records
INFO:__main__:Data transformation completed successfully for mode: silver
INFO:__main__:Starting data load for mode: silver
DEBUG:py4j.clientserver:Command to send: r
u
PythonUtils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.api.python.PythonUtils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.api.python.PythonUtils
toArray
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: i
java.util.ArrayList
e

DEBUG:py4j.clientserver:Answer received: !ylo230
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.api.python.PythonUtils
toArray
ro230
e

DEBUG:py4j.clientserver:Answer received: !yto231
DEBUG:py4j.clientserver:Command to send: c
o57
sql
sCREATE DATABASE IF NOT EXISTS iceberg_catalog.neo_db
ro231
e

DEBUG:py4j.clientserver:Command to send: m
d
o230
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Answer received: !xro232
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.catalyst.parser.ParseException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.AnalysisException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.streaming.StreamingQueryException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.execution.QueryExecutionException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.NumberFormatException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.IllegalArgumentException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.ArithmeticException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.UnsupportedOperationException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.ArrayIndexOutOfBoundsException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.time.DateTimeException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.SparkRuntimeException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: r
u
py4j
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
py4j.reflection.TypeUtil
rj
e

DEBUG:py4j.clientserver:Answer received: !ycpy4j.reflection.TypeUtil
DEBUG:py4j.clientserver:Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.SparkUpgradeException
ro232
e

DEBUG:py4j.clientserver:Answer received: !ybfalse
DEBUG:py4j.clientserver:Command to send: c
o232
getCause
e

DEBUG:py4j.clientserver:Answer received: !yn
DEBUG:py4j.clientserver:Command to send: r
u
org
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.util
rj
e

DEBUG:py4j.clientserver:Answer received: !yp
DEBUG:py4j.clientserver:Command to send: r
u
org.apache.spark.util.Utils
rj
e

DEBUG:py4j.clientserver:Answer received: !ycorg.apache.spark.util.Utils
DEBUG:py4j.clientserver:Command to send: r
m
org.apache.spark.util.Utils
exceptionString
e

DEBUG:py4j.clientserver:Answer received: !ym
DEBUG:py4j.clientserver:Command to send: c
z:org.apache.spark.util.Utils
exceptionString
ro232
e

DEBUG:py4j.clientserver:Answer received: !ysjava.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'\n	at org.apache.hadoop.fs.impl.FlagSet.buildFlagSet(FlagSet.java:323)\n	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:743)\n	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n	at org.apache.iceberg.hadoop.Util.getFs(Util.java:55)\n	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)\n	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:277)\n	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:331)\n	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:153)\n	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:752)\n	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:549)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n	at scala.collection.immutable.List.foldLeft(List.scala:91)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n	at scala.collection.immutable.List.foreach(List.scala:431)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n	at java.base/java.lang.reflect.Method.invoke(Method.java:569)\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n	at py4j.Gateway.invoke(Gateway.java:282)\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n	at java.base/java.lang.Thread.run(Thread.java:840)\n
DEBUG:py4j.clientserver:Command to send: c
o232
toString
e

DEBUG:py4j.clientserver:Answer received: !ysjava.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'
DEBUG:py4j.clientserver:Command to send: p
ro232
e

DEBUG:py4j.clientserver:Answer received: !ysjava.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'\n	at org.apache.hadoop.fs.impl.FlagSet.buildFlagSet(FlagSet.java:323)\n	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:743)\n	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n	at org.apache.iceberg.hadoop.Util.getFs(Util.java:55)\n	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)\n	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:277)\n	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:331)\n	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:153)\n	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:752)\n	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:549)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n	at scala.collection.immutable.List.foldLeft(List.scala:91)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n	at scala.collection.immutable.List.foreach(List.scala:431)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n	at java.base/java.lang.reflect.Method.invoke(Method.java:569)\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n	at py4j.Gateway.invoke(Gateway.java:282)\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n	at java.base/java.lang.Thread.run(Thread.java:840)\n
ERROR:__main__:Data load failed for mode silver: An error occurred while calling o57.sql.
: java.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'
	at org.apache.hadoop.fs.impl.FlagSet.buildFlagSet(FlagSet.java:323)
	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:743)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
	at org.apache.iceberg.hadoop.Util.getFs(Util.java:55)
	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)
	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:277)
	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:331)
	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:153)
	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:752)
	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)
	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)
	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)
	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)
	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)
	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:549)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
	at scala.collection.immutable.List.foldLeft(List.scala:91)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:840)

DEBUG:py4j.clientserver:Command to send: p
ro232
e

DEBUG:py4j.clientserver:Answer received: !ysjava.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'\n	at org.apache.hadoop.fs.impl.FlagSet.buildFlagSet(FlagSet.java:323)\n	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:743)\n	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n	at org.apache.iceberg.hadoop.Util.getFs(Util.java:55)\n	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)\n	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:277)\n	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:331)\n	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:153)\n	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:752)\n	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:549)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n	at scala.collection.immutable.List.foldLeft(List.scala:91)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n	at scala.collection.immutable.List.foreach(List.scala:431)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n	at java.base/java.lang.reflect.Method.invoke(Method.java:569)\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n	at py4j.Gateway.invoke(Gateway.java:282)\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n	at java.base/java.lang.Thread.run(Thread.java:840)\n
DEBUG:py4j.clientserver:Command to send: p
ro232
e

DEBUG:py4j.clientserver:Answer received: !ysjava.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'\n	at org.apache.hadoop.fs.impl.FlagSet.buildFlagSet(FlagSet.java:323)\n	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:743)\n	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n	at org.apache.iceberg.hadoop.Util.getFs(Util.java:55)\n	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)\n	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:277)\n	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:331)\n	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:153)\n	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:752)\n	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:549)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n	at scala.collection.immutable.List.foldLeft(List.scala:91)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n	at scala.collection.immutable.List.foreach(List.scala:431)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n	at java.base/java.lang.reflect.Method.invoke(Method.java:569)\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n	at py4j.Gateway.invoke(Gateway.java:282)\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n	at java.base/java.lang.Thread.run(Thread.java:840)\n
DEBUG:py4j.clientserver:Command to send: p
ro232
e

DEBUG:py4j.clientserver:Answer received: !ysjava.lang.NoSuchMethodError: 'java.util.EnumSet org.apache.hadoop.conf.Configuration.getEnumSet(java.lang.String, java.lang.Class, boolean)'\n	at org.apache.hadoop.fs.impl.FlagSet.buildFlagSet(FlagSet.java:323)\n	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:743)\n	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n	at org.apache.iceberg.hadoop.Util.getFs(Util.java:55)\n	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)\n	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:277)\n	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:331)\n	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:153)\n	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:752)\n	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:549)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n	at scala.collection.immutable.List.foldLeft(List.scala:91)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n	at scala.collection.immutable.List.foreach(List.scala:431)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n	at java.base/java.lang.reflect.Method.invoke(Method.java:569)\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n	at py4j.Gateway.invoke(Gateway.java:282)\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n	at java.base/java.lang.Thread.run(Thread.java:840)\n
DEBUG:py4j.clientserver:Command to send: m
d
o197
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o198
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o200
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o201
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o202
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o203
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o204
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o205
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o206
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o207
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o209
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o210
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o211
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o212
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o213
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o214
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o215
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o216
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o218
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o219
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o220
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o221
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o222
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o223
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o225
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o227
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o228
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o75
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o91
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o123
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o160
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o193
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o194
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o196
e

DEBUG:py4j.clientserver:Answer received: !yv
DEBUG:py4j.clientserver:Command to send: m
d
o188
e

DEBUG:py4j.clientserver:Answer received: !yv
